{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Phrase-based Poem Generation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scWzb4P2EStk"
      },
      "source": [
        "## Reading dataset from drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOcK62MQ5AjB"
      },
      "source": [
        "from google.colab import drive\n",
        "pth = \"/content/drive/MyDrive/BE_Project/poem/\"\n",
        "dest = \"/temp/test.csv\"\n",
        "drive.mount(pth[:14])\n",
        "\n",
        "import shutil\n",
        "shutil.copy(pth + \"dataset/test.csv\", dest)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4V0pz_lDEdzG"
      },
      "source": [
        "## Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d52YNQkBEb7h"
      },
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Attention, Dropout, Dense\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Bidirectional\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnU_z9O4Elal"
      },
      "source": [
        "## Reading and cleaning dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yif6WawRE2VX"
      },
      "source": [
        "# Reading data from csv\n",
        "data = pd.read_csv(dest, usecols=['Content'], nrows=600)['Content']\n",
        "\n",
        "corpus = []\n",
        "for poem in data:\n",
        "    [corpus.append(text) for text in poem.lower().replace('\\r', '').split(\"\\n\")]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMNO_9-QFS52"
      },
      "source": [
        "## Tokenizing texts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXv1dOdWFUcb"
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "\n",
        "# Saving the tokenized text\n",
        "pickle.dump(tokenizer, open(pth + 'tokenizer(test_csv).pkl', 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsoNvMOzFieb"
      },
      "source": [
        "## Tokenizing texts to sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-2TfyYLFhav"
      },
      "source": [
        "total_words = len(tokenizer.word_index) + 1\n",
        "input_sequences = []\n",
        "\n",
        "for line in corpus:\n",
        "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "    for i in range (1, len(token_list)):\n",
        "        n_gram_sequence = token_list[ : i+1]\n",
        "        input_sequences.append(n_gram_sequence)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2tiTQg1FkoQ"
      },
      "source": [
        "## Adding padding to sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASxwkIAMFtdd"
      },
      "source": [
        "max_sequence_len = max([len(x) for x in input_sequences])\n",
        "input_sequences = np.array(pad_sequences(input_sequences, maxlen = max_sequence_len, padding = 'pre'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9oV-vsESF1Kv"
      },
      "source": [
        "## Plotting accuracy and loss graphs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vt1cRn4yF0br"
      },
      "source": [
        "def plot_graphs(history, string):\n",
        "    plt.plot(history.history[string])\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(string)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQfhQ216GTK3"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idLGykzgGNUO"
      },
      "source": [
        "### Preparing data for model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bce3JypsGQcM"
      },
      "source": [
        "xs = input_sequences[:, :-1]\n",
        "labels = input_sequences[:, -1]\n",
        "ys = tf.keras.utils.to_categorical(labels, num_classes = total_words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEMN73UFGYV_"
      },
      "source": [
        "### Creating Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cId-Pzx6GWd-"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(total_words, 100, input_length=max_sequence_len-1))\n",
        "model.add(Bidirectional(LSTM(150, return_sequences = True)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(total_words/2, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
        "model.add(Dense(total_words, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EY5cq7ISGfmE"
      },
      "source": [
        "### Compiling Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHoshBoTGdv6"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.0001), metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIvu0cTJGqQ6"
      },
      "source": [
        "### Creating checkpoints and reducing learning rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kx73DKunGt8R"
      },
      "source": [
        "checkpoint = ModelCheckpoint(pth + \"poem_generation(test_csv).h5\", monitor='loss', verbose=1, save_best_only=True, mode='auto')\n",
        "reduce = ReduceLROnPlateau(monitor='loss', factor=0.2, patience=3, min_lr=0.0001, verbose = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beOaPdFlGvJt"
      },
      "source": [
        "### Fitting model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtmZH0YfG0J6"
      },
      "source": [
        "history = model.fit(xs, ys, epochs=200, verbose=1, callbacks=[checkpoint, reduce])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-iOywPqKHrxt"
      },
      "source": [
        "### Plotting accuracy and loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKJerWBj_smP"
      },
      "source": [
        "plot_graphs(history, 'accuracy')\n",
        "plot_graphs(history, 'loss')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEgKL47OH0uN"
      },
      "source": [
        "# Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8YIRI6V929o"
      },
      "source": [
        "## Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiCZmGbW9kpF"
      },
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXr_wbPO-DOa"
      },
      "source": [
        "## Loading model and tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIC67tlX900S"
      },
      "source": [
        "from google.colab import drive\n",
        "pth = \"/content/drive/MyDrive/BE_Project/poem/\"\n",
        "drive.mount(pth[:14])\n",
        "\n",
        "model = load_model(pth + 'poem_generation(csv_txt).h5')\n",
        "tokenizer = pickle.load(open(pth + 'tokenizer.pkl', 'rb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDoO8AEf-JlJ"
      },
      "source": [
        "## Poem Generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eP5Jusr1P-I5"
      },
      "source": [
        "# Inputs\n",
        "seed_text = input(\"\\033[1mEnter phrase:\\033[0m \") #I dont know where hes stationed, be it Cork or in Killarney\n",
        "next_words = int(input(\"\\033[1mEnter number of stanzas:\\033[0m \"))\n",
        "len_phrase = len(seed_text)\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "words = list(word_index.keys())\n",
        "values = list(word_index.values())\n",
        "\n",
        "for i in range (next_words*8*4):\n",
        "  token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "  token_list = pad_sequences([token_list], maxlen=85, padding='pre')\n",
        "  predicted = np.argmax(model.predict_on_batch(token_list))\n",
        "  output_word = \"\"\n",
        "  for index in values:\n",
        "    if index == predicted:\n",
        "      output_word = words[values.index(index)]\n",
        "      break\n",
        "  seed_text += \" \" + output_word\n",
        "  if i <= (next_words*8*4 - 8):\n",
        "    if (i + 1) % 32 == 0:\n",
        "        seed_text += \"\\n\"\n",
        "    if (i + 1) % 8 == 0:\n",
        "        seed_text += \"\\n\"\n",
        "\n",
        "seed_text = seed_text[ : len_phrase] + \"\\033[0m\" + seed_text[len_phrase: ]\n",
        "print(\"\\n\\n\\033[1mGenerated Poem\\n\" + seed_text.replace(\"\\n \", \"\\n\"))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}